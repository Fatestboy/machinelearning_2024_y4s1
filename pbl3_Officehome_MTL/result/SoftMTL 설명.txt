글로벌 평균 풀링(Global Average Pooling, GAP)은 합성곱 신경망에서 공간적 차원을 축소하여 각 채널의 대표값을 얻는 방법입니다. 이를 통해 각 채널의 특징을 압축된 벡터로 표현할 수 있습니다.

### 주요 개념과 특징

1. **평균 풀링**:
   - 평균 풀링(Average Pooling)은 지정된 커널 크기를 가진 영역의 픽셀 값을 평균내어 축소된 특징 맵을 생성하는 과정입니다.
   - 예를 들어, 4x4 크기의 특징 맵을 2x2 커널로 평균 풀링하면 2x2 크기의 작은 특징 맵을 얻을 수 있습니다.

2. **글로벌 평균 풀링의 역할**:
   - GAP는 공간적인 전체 크기(`Height`와 `Width`)를 하나의 픽셀로 축소하는 과정입니다.
   - 각 채널에 대해 전체 영역의 픽셀 값을 평균내어 단일 값으로 축소합니다.
   - 따라서 특징 맵의 `(Height, Width)`를 모두 1로 줄이면서 채널 수는 그대로 유지합니다.

3. **글로벌 평균 풀링의 장점**:
   - **차원 축소**: `Height`와 `Width` 차원을 1로 줄여 차원이 크게 축소되어 계산 효율이 높아집니다.
   - **특징 요약**: 각 채널별로 이미지 전역의 특징을 하나의 대표값으로 요약합니다.
   - **과적합 방지**: 완전 연결 레이어가 아닌 풀링 방식으로 차원 축소를 수행하므로, 파라미터 수가 적어 과적합을 방지할 수 있습니다.
   - **해석 가능성**: GAP로 축소된 각 채널은 특정 특징의 전체적인 중요도를 표현하여 해석하기 쉬운 특성을 제공합니다.

### GAP의 작동 예시

1. **입력**: `(Batch Size, Channels, Height, Width)` 형태의 특징 맵을 입력으로 받습니다.
2. **평균 계산**:
   - 각 채널에 대해 `(Height, Width)` 영역의 모든 값을 평균내어 단일 값으로 축소합니다.
   - 이렇게 축소된 출력은 `(Batch Size, Channels, 1, 1)` 형태가 됩니다.
3. **평탄화**:
   - 최종적으로 평탄화하여 `(Batch Size, Channels)`의 2차원 벡터로 변환합니다.

### 예시 코드

PyTorch의 `nn.AdaptiveAvgPool2d`를 사용하여 글로벌 평균 풀링을 구현할 수 있습니다.

```python
import torch
import torch.nn as nn

# 예시로 임의의 특징 맵 텐서 생성 (배치 크기=2, 채널=3, 높이=4, 너비=4)
input_tensor = torch.randn(2, 3, 4, 4)

# 글로벌 평균 풀링 레이어 정의
gap = nn.AdaptiveAvgPool2d((1, 1))

# GAP 적용하여 출력 생성
output_tensor = gap(input_tensor)

# 결과 평탄화하여 `(Batch Size, Channels)` 형태로 변환
flattened_output = torch.flatten(output_tensor, start_dim=1)

print(flattened_output)
```

이렇게 글로벌 평균 풀링을 통해 각 채널의 전역적 특징을 단일 벡터로 표현할 수 있습니다.

각 도메인과 카테고리별 특징 벡터는 두 가지 주요 과정으로 생성되고 출력됩니다. 먼저, EfficientNet 모델을 통해 각 특징 벡터를 추출하고, 이 벡터를 분류기(classifier)를 통해 도메인 또는 카테고리의 클래스로 예측하는 과정을 거칩니다.

### 과정 설명:

1. **EfficientNet에서 특징 맵 추출**:
   - `self.base_model_domain(x)[-1]`과 `self.base_model_category(x)[-1]`을 통해 각 EfficientNet 모델에서 마지막 특징 맵을 추출합니다.
   - EfficientNet은 합성곱 층을 사용하여 이미지를 여러 계층을 통해 처리하면서 다양한 수준의 특징을 추출합니다.
   - `[-1]`은 네트워크의 마지막 계층의 출력(가장 높은 수준의 특징)을 의미하며, 이 특징 맵은 `(Batch Size, Channel, Height, Width)` 형태의 텐서로 나타납니다.

2. **글로벌 평균 풀링으로 특징 맵을 벡터로 변환**:
   - `self.pool`은 `nn.AdaptiveAvgPool2d((1, 1))`로 정의된 풀링 레이어입니다.
   - 각 채널에서 모든 공간 정보를 평균내어 `Height`와 `Width` 차원을 1로 축소합니다.
   - 이 과정을 통해 특징 맵은 `(Batch Size, Channel, 1, 1)`에서 `(Batch Size, Channel)`로 변환됩니다.

3. **평탄화(Flatten)하여 2차원 벡터로 변환**:
   - `torch.flatten(features_domain, start_dim=1)`과 `torch.flatten(features_category, start_dim=1)`을 사용하여 2차원 벡터 형태로 평탄화합니다.
   - 이 작업을 통해 각 특징 벡터는 `(Batch Size, Channel)` 형태의 2차원 텐서로 나타납니다.

4. **특징 벡터 결합**:
   - `torch.cat((features_domain, features_category), dim=1)`을 사용하여 두 특징 벡터를 나란히 이어붙입니다.
   - 결합된 벡터는 `(Batch Size, feature_dim_domain + feature_dim_category)` 형태가 됩니다.

5. **분류기(classifier)를 통한 예측**:
   - **도메인 분류**: `self.domain_classifier(shared_features)`는 결합된 특징 벡터를 입력받아 도메인 클래스에 대한 예측을 생성합니다.
     - 이 분류기는 결합된 특징 벡터를 입력으로 받아, `num_domains` 크기의 출력 벡터를 생성합니다.
   - **카테고리 분류**: `self.category_classifier(shared_features)`는 동일한 특징 벡터를 입력받아 카테고리 클래스에 대한 예측을 생성합니다.
     - 이 분류기는 `num_categories` 크기의 출력 벡터를 생성합니다.

### 요약
- 각 도메인과 카테고리별 특징 벡터는 EfficientNet을 통해 각각 추출됩니다.
- 이 벡터는 글로벌 평균 풀링과 평탄화 과정을 통해 `(Batch Size, Channel)` 형태의 벡터로 변환됩니다.
- 두 벡터는 결합되어 공유된 특징 벡터를 생성하고, 각각의 분류기를 통해 도메인 및 카테고리 클래스에 대한 예측으로 변환됩니다.

위 코드에서 `shared_features`는 두 개의 EfficientNet 모델에서 추출된 특징 벡터를 결합하여 생성됩니다. 이를 통해 공유된 특징 벡터는 두 모델의 마지막 특징 맵이 합쳐진 구조로 표현됩니다.

### 설명:

1. **특징 추출**:
   - 각 EfficientNet 모델에서 `features_domain`과 `features_category`라는 마지막 특징 맵을 추출합니다. 이 두 특징 맵은 `(Batch Size, Channel, 1, 1)` 형태의 텐서입니다. 
   - 여기서 `Channel`은 각 EfficientNet의 마지막 특징 맵의 채널 수를 나타냅니다.

2. **평균 풀링**:
   - `self.pool`을 통해 특징 맵을 `(1, 1)` 크기로 압축하여 `(Batch Size, Channel, 1, 1)` 형태에서 `(Batch Size, Channel)`로 변환합니다.
   - 각 채널은 입력 이미지의 특징을 나타내는 대표적인 값이 됩니다.

3. **평탄화**:
   - `torch.flatten`으로 두 특징 맵 모두 `(Batch Size, Channel)` 형태로 평탄화합니다.
   - `features_domain`과 `features_category`는 각각 `(Batch Size, feature_dim_domain)`와 `(Batch Size, feature_dim_category)` 형태가 됩니다.

4. **특징 결합**:
   - `torch.cat`을 사용해 두 특징 벡터를 하나의 벡터로 합칩니다.
   - 두 번째 차원(`dim=1`)을 기준으로 병합하여 `(Batch Size, feature_dim_domain + feature_dim_category)` 형태의 `shared_features` 벡터가 생성됩니다.

### 요약
- **`shared_features`**:
  - `shared_features`는 각 EfficientNet 모델의 마지막 특징 맵을 합친 형태의 벡터입니다.
  - 이 벡터는 `(Batch Size, feature_dim_domain + feature_dim_category)` 구조로, 각 채널에 대한 정보가 나란히 합쳐져 있습니다.

### 활용
이 공유된 특징 벡터는 각각의 분류기 레이어(`domain_classifier`, `category_classifier`)에 전달되어, 두 가지 작업(도메인 및 카테고리 분류)을 위한 예측에 활용됩니다.



공유된 특징 벡터를 분류기에 입력하면, 다음과 같은 영향과 장점이 있습니다.

### 1. **다양한 특징 정보 통합**:
- **결합된 정보**:
  - 각 EfficientNet 모델의 마지막 특징 벡터에는 해당 작업(도메인 또는 카테고리)을 위한 특징이 포함되어 있습니다.
  - 결합된 특징 벡터는 두 작업의 특징을 모두 포함하므로, 각각의 분류기에 더 풍부하고 다양한 정보를 제공합니다.
  - 이로써 분류기가 더 정확한 분류를 수행할 수 있게 됩니다.

### 2. **간섭을 통한 일반화 향상**:
- **상호 간섭 효과**:
  - 두 모델의 특징을 합치면 각 작업 간의 특징이 상호 간섭을 일으켜 다른 작업에서 얻은 정보를 활용합니다.
  - 도메인 분류를 위해 추출된 특징이 카테고리 분류에 도움이 될 수 있고, 반대로 카테고리 분류를 위해 추출된 정보가 도메인 분류에 기여할 수 있습니다.
  - 이를 통해 두 작업 모두 일반화 성능이 향상될 수 있습니다.

### 3. **과적합 위험 감소**:
- **공유된 표현**:
  - 공유된 특징 벡터는 두 작업이 동일한 이미지에서 추출한 공통 특징을 포함합니다.
  - 이런 공통 특징을 활용하여 특정 작업에만 집중하지 않고 다양한 분류 기준을 고려함으로써, 과적합을 방지하고 더 일반화된 모델을 만들 수 있습니다.

### 4. **멀티태스킹의 이점**:
- **관련성 활용**:
  - 두 작업이 어느 정도 관련성이 있을 때, 결합된 특징 벡터는 각 작업의 관계를 활용하여 최종 분류에서 시너지를 창출할 수 있습니다.
  - 예를 들어, 특정 도메인에서만 존재하는 카테고리를 분류하는 경우, 해당 도메인에 속한다는 정보가 분류에 도움이 될 수 있습니다.

### 요약
- 공유된 특징 벡터는 두 모델의 정보를 결합하여 각 분류기가 더 풍부하고 일반화된 정보를 사용할 수 있도록 돕습니다.
- 이를 통해 모델의 학습 및 분류 과정에서 작업 간 상호 간섭이 일어나며, 이로 인해 각 작업의 예측 정확도 및 일반화 능력이 향상됩니다.